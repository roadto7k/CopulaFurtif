# dash_copula_app.py
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Dash app: Formation (screening) + Copula fit & diagnostics.

Prereqs:
- Artifacts generated by pipeline_main.py under ./artifacts
  - formation_summary.csv, candidate_pairs.csv, spreads/*.csv, meta.json
- Optional copula backends:
  * CopulaFurtif (preferred if available), or
  * statsmodels >= 0.13 (Gaussian, Student-t, Clayton, Gumbel, Frank)

Run:
  python dash_copula_app.py --artifacts ./artifacts --reference BTCUSDT
"""
import json
from pathlib import Path
from typing import Tuple, List

import numpy as np
import pandas as pd

import dash
import dash_bootstrap_components as dbc
from dash import dcc, html, Input, Output, State, dash_table
import plotly.graph_objs as go
import plotly.express as px

from CopulaFurtif.core.copulas.domain.estimation.estimation import pseudo_obs
from CopulaFurtif.core.copulas.domain.copula_type import CopulaType
from CopulaFurtif.core.copulas.domain.factories.copula_factory import CopulaFactory
from CopulaFurtif.core.copulas.application.services.fit_copula import CopulaFitter

# ---- Optional imports for copulas ----
HAS_COPULAFURTIF = False
HAS_SM_COPULA = False
try:
    # If you have this third-party package installed
    from CopulaFurtif.copulas import CopulaFactory, CopulaType
    from CopulaFurtif.copulas import CopulaDiagnostics, CopulaFitter
    HAS_COPULAFURTIF = True
except Exception:
    pass

try:
    # Statsmodels Copula API (0.13+)
    from statsmodels.distributions.copula.api import (
        GaussianCopula, StudentTCopula, ClaytonCopula, FrankCopula, GumbelCopula
    )
    HAS_SM_COPULA = True
except Exception:
    pass


DEFAULT_THEME = dbc.themes.CYBORG


# -------------- IO helpers --------------
def load_artifacts(artifacts_dir: str):
    base = Path(artifacts_dir)
    paths = {
        "summary": base / "formation_summary.csv",
        "top": base / "top_candidates.csv",
        "pairs": base / "candidate_pairs.csv",
        "spreads_dir": base / "spreads",
        "meta": base / "meta.json",
    }

    dfs = {}
    for k in ["summary", "top", "pairs"]:
        try:
            dfs[k] = pd.read_csv(paths[k]) if paths[k].exists() else pd.DataFrame()
        except Exception:
            dfs[k] = pd.DataFrame()

    spreads = {}
    if paths["spreads_dir"].exists():
        for fp in sorted(paths["spreads_dir"].glob("*.csv")):
            try:
                df = pd.read_csv(fp, index_col=0, parse_dates=True)
                col = df.columns[0]
                spreads[fp.stem] = df[col].rename(fp.stem)
            except Exception:
                continue

    meta = {}
    if paths["meta"].exists():
        try:
            meta = json.loads(paths["meta"].read_text())
        except Exception:
            pass

    return dfs, spreads, paths, meta


# -------------- Transform helpers --------------



def fig_empirical_copula(u: np.ndarray, v: np.ndarray, nbins: int = 30) -> go.Figure:
    hist, xe, ye = np.histogram2d(u, v, bins=nbins, range=[[0, 1], [0, 1]], density=True)
    fig = go.Figure(data=go.Heatmap(z=hist.T, x=xe, y=ye, coloraxis="coloraxis"))
    fig.update_layout(
        template="plotly_dark",
        title="Empirical copula density (pseudo-observations)",
        xaxis_title="u",
        yaxis_title="v",
        coloraxis=dict(colorscale="Viridis"),
    )
    return fig


def fig_scatter_uv(u: np.ndarray, v: np.ndarray, nmax: int = 5000) -> go.Figure:
    if len(u) > nmax:
        idx = np.linspace(0, len(u) - 1, nmax).astype(int)
        uu, vv = u[idx], v[idx]
    else:
        uu, vv = u, v
    fig = go.Figure()
    fig.add_trace(go.Scattergl(x=uu, y=vv, mode="markers", marker=dict(size=4), name="(u,v)"))
    fig.update_layout(template="plotly_dark", title="Pseudo-observations scatter", xaxis_title="u", yaxis_title="v")
    return fig


def aic(loglik: float, k: int) -> float:
    return 2 * k - 2 * loglik


# -------------- Copula fitting --------------
# def fit_copulas(u: np.ndarray, v: np.ndarray) -> Tuple[pd.DataFrame, List[str]]:
#     """
#     Fit common bivariate copulas on pseudo-observations.
#     Returns (df, messages) with: name, params, loglik, aic, tail_dep_L, tail_dep_U
#     """
#     from scipy.optimize import minimize
#
#     msgs, results = [], []
#     u = np.asarray(u).reshape(-1, 1)
#     v = np.asarray(v).reshape(-1, 1)
#     data = np.hstack([u, v])
#
#     # Prefer CopulaFurtif if available
#     if HAS_COPULAFURTIF:
#         candidates = [
#             ("Gaussian", CopulaType.GAUSSIAN),
#             ("Student-t", CopulaType.STUDENT),
#             ("Clayton", CopulaType.CLAYTON),
#             ("Gumbel", CopulaType.GUMBEL),
#             ("Frank", CopulaType.FRANK),
#         ]
#         for name, ctype in candidates:
#             try:
#                 cop = CopulaFactory.create(ctype)
#                 fitted_params, loglik = CopulaFitter().fit_mle([u.ravel(), v.ravel()], copula=cop, known_parameters=False)
#                 cop.set_parameters(np.array(fitted_params))
#                 try:
#                     tdL, tdU = CopulaDiagnostics.tail_dependence(cop)
#                 except Exception:
#                     tdL = tdU = np.nan
#                 results.append(
#                     dict(
#                         name=name,
#                         params=np.array(fitted_params, dtype=float),
#                         loglik=float(loglik),
#                         aic=float(aic(loglik, len(np.atleast_1d(fitted_params)))),
#                         tail_dep_L=tdL,
#                         tail_dep_U=tdU,
#                     )
#                 )
#             except Exception as e:
#                 msgs.append(f"{name} (CopulaFurtif) fit failed: {e}")
#
#     elif HAS_SM_COPULA:
#         # Statsmodels small MLE wrappers
#         def fit_sm(name, cls):
#             try:
#                 # Elliptical (rho in (-1,1)), Student-t also df>2
#                 if name.lower().startswith("gaussian") or name.lower().startswith("student"):
#                     rho0 = 0.0
#                     if "student" in name.lower():
#                         df0 = 5.0
#
#                         def nll(x):
#                             rho, df = np.tanh(x[0]), 2.1 + np.exp(x[1])
#                             c = cls(rho, df=df)
#                             return -np.sum(c.logpdf(data))
#
#                         res = minimize(nll, x0=np.array([np.arctanh(rho0 + 1e-6), np.log(df0 - 2.1 + 1e-6)]), method="Nelder-Mead")
#                         rho_hat, df_hat = np.tanh(res.x[0]), 2.1 + np.exp(res.x[1])
#                         cop_hat = cls(rho_hat, df=df_hat)
#                         ll = np.sum(cop_hat.logpdf(data))
#                         return dict(name=name, params=np.array([rho_hat, df_hat]), loglik=float(ll), aic=float(aic(ll, 2)),
#                                     tail_dep_L=np.nan, tail_dep_U=np.nan)
#                     else:
#                         def nll(x):
#                             rho = np.tanh(x[0])
#                             c = cls(rho)
#                             return -np.sum(c.logpdf(data))
#
#                         res = minimize(nll, x0=np.array([np.arctanh(rho0 + 1e-6)]), method="Nelder-Mead")
#                         rho_hat = np.tanh(res.x[0])
#                         cop_hat = cls(rho_hat)
#                         ll = np.sum(cop_hat.logpdf(data))
#                         return dict(name=name, params=np.array([rho_hat]), loglik=float(ll), aic=float(aic(ll, 1)),
#                                     tail_dep_L=0.0, tail_dep_U=0.0)
#                 # Archimedean (theta>0): Clayton/Gumbel/Frank
#                 else:
#                     th0 = 1.0
#
#                     def nll(x):
#                         theta = 1e-6 + np.exp(x[0])
#                         c = cls(theta)
#                         return -np.sum(c.logpdf(data))
#
#                     res = minimize(nll, x0=np.array([np.log(th0)]), method="Nelder-Mead")
#                     th_hat = 1e-6 + np.exp(res.x[0])
#                     cop_hat = cls(th_hat)
#                     ll = np.sum(cop_hat.logpdf(data))
#                     # Tail dep formulas:
#                     tdL = tdU = 0.0
#                     lname = name.lower()
#                     if lname.startswith("clayton"):
#                         tdL, tdU = float(2 ** (-1 / th_hat)), 0.0
#                     elif lname.startswith("gumbel"):
#                         tdL, tdU = 0.0, float(2 - 2 ** (1 / th_hat))
#                     elif lname.startswith("frank"):
#                         tdL = tdU = 0.0
#                     return dict(name=name, params=np.array([th_hat]), loglik=float(ll), aic=float(aic(ll, 1)),
#                                 tail_dep_L=tdL, tail_dep_U=tdU)
#             except Exception as e:
#                 msgs.append(f"{name} (statsmodels) fit failed: {e}")
#                 return None
#
#         fams = [
#             ("Gaussian", GaussianCopula),
#             ("Student-t", StudentTCopula),
#             ("Clayton", ClaytonCopula),
#             ("Gumbel", GumbelCopula),
#             ("Frank", FrankCopula),
#         ]
#         for name, cls in fams:
#             out = fit_sm(name, cls)
#             if out is not None:
#                 results.append(out)
#
#     else:
#         msgs.append("Aucune librairie de copules trouvée. Installez 'CopulaFurtif' ou 'statsmodels>=0.13'.")
#
#     df = pd.DataFrame(results).sort_values("aic", ascending=True).reset_index(drop=True) if results else \
#          pd.DataFrame(columns=["name", "params", "loglik", "aic", "tail_dep_L", "tail_dep_U"])
#     return df, msgs

def fit_copulas(u: np.ndarray, v: np.ndarray) -> Tuple[pd.DataFrame, List[str]]:
    """
    Fit rapide des copules bivariées via inversion de Kendall (CopulaFitter.fit_tau),
    plus tail dependence et (optionnel) loglik/AIC si disponible.
    Retourne (df, msgs) avec: name, params, loglik, aic, tail_dep_L, tail_dep_U
    """
    from scipy.optimize import minimize  # utilisé dans le fallback statsmodels
    msgs, results = [], []

    # normalisation des entrées
    u = np.asarray(u).ravel()
    v = np.asarray(v).ravel()
    data = np.column_stack([u, v])

    def _aic(ll, k: int) -> float:
        return np.nan if not np.isfinite(ll) else (2 * k - 2 * ll)

    # ---------- Chemin prioritaire : CopulaFurtif via fit_tau ----------
    if HAS_COPULAFURTIF:
        # imports locaux pour éviter de casser si la lib n'est pas installée

        fitter = CopulaFitter()
        candidates = [
            ("Gaussian",  CopulaType.GAUSSIAN),
            ("Student-t", CopulaType.STUDENT),
            ("Clayton",   CopulaType.CLAYTON),
            ("Gumbel",    CopulaType.GUMBEL),
            ("Frank",     CopulaType.FRANK),
        ]

        for name, ctype in candidates:
            try:
                cop = CopulaFactory.create(ctype)

                # 1) Estimation ultra-rapide par inversion de τ (fit_tau rankifie en interne)
                params = np.array(fitter.fit_tau(data=(u, v), copula=cop), dtype=float)  # fit_tau init-only

                # 2) Dépendances de queues (formules fermées exposées par la copule)
                try:
                    tdL = float(cop.LTDC(params))
                except Exception:
                    tdL = np.nan
                try:
                    tdU = float(cop.UTDC(params))
                except Exception:
                    tdU = np.nan

                # 3) Tentative de log-likelihood au point 'params' (optionnel)
                ll = np.nan
                for call in (
                    lambda: np.sum(cop.logpdf(data)),              # certaines implémentations lisent l'état interne
                    lambda: np.sum(cop.logpdf(data, params)),     # d’autres exigent params à l’appel
                    lambda: np.sum(np.log(cop.pdf(data))),
                    lambda: np.sum(np.log(cop.pdf(data, params))),
                ):
                    try:
                        val = float(call())
                        if np.isfinite(val):
                            ll = val
                            break
                    except Exception:
                        pass

                aic_val = _aic(ll, len(np.atleast_1d(params)))

                results.append(
                    dict(
                        name=name,
                        params=params,
                        loglik=ll,
                        aic=aic_val,
                        tail_dep_L=tdL,
                        tail_dep_U=tdU,
                    )
                )
            except Exception as e:
                msgs.append(f"{name} (fit_tau) failed: {e}")

    # ---------- Fallback : statsmodels (conserve ton bloc existant) ----------
    elif HAS_SM_COPULA:
        def fit_sm(name, cls):
            try:
                # Elliptiques
                if name.lower().startswith("gaussian") or name.lower().startswith("student"):
                    rho0 = 0.0
                    if "student" in name.lower():
                        df0 = 5.0

                        def nll(x):
                            rho, df = np.tanh(x[0]), 2.1 + np.exp(x[1])
                            c = cls(rho, df=df)
                            return -np.sum(c.logpdf(data))

                        res = minimize(nll, x0=np.array([np.arctanh(rho0 + 1e-6), np.log(df0 - 2.1 + 1e-6)]),
                                       method="Nelder-Mead")
                        rho_hat, df_hat = np.tanh(res.x[0]), 2.1 + np.exp(res.x[1])
                        cop_hat = cls(rho_hat, df=df_hat)
                        ll = np.sum(cop_hat.logpdf(data))
                        return dict(name=name, params=np.array([rho_hat, df_hat]), loglik=float(ll), aic=float(_aic(ll, 2)),
                                    tail_dep_L=np.nan, tail_dep_U=np.nan)
                    else:
                        def nll(x):
                            rho = np.tanh(x[0])
                            c = cls(rho)
                            return -np.sum(c.logpdf(data))

                        res = minimize(nll, x0=np.array([np.arctanh(rho0 + 1e-6)]), method="Nelder-Mead")
                        rho_hat = np.tanh(res.x[0])
                        cop_hat = cls(rho_hat)
                        ll = np.sum(cop_hat.logpdf(data))
                        return dict(name=name, params=np.array([rho_hat]), loglik=float(ll), aic=float(_aic(ll, 1)),
                                    tail_dep_L=0.0, tail_dep_U=0.0)
                # Archimédiennes
                else:
                    th0 = 1.0

                    def nll(x):
                        theta = 1e-6 + np.exp(x[0])
                        c = cls(theta)
                        return -np.sum(c.logpdf(data))

                    res = minimize(nll, x0=np.array([np.log(th0)]), method="Nelder-Mead")
                    th_hat = 1e-6 + np.exp(res.x[0])
                    cop_hat = cls(th_hat)
                    ll = np.sum(cop_hat.logpdf(data))
                    tdL = tdU = 0.0
                    lname = name.lower()
                    if lname.startswith("clayton"):
                        tdL, tdU = float(2 ** (-1 / th_hat)), 0.0
                    elif lname.startswith("gumbel"):
                        tdL, tdU = 0.0, float(2 - 2 ** (1 / th_hat))
                    return dict(name=name, params=np.array([th_hat]), loglik=float(ll), aic=float(_aic(ll, 1)),
                                tail_dep_L=tdL, tail_dep_U=tdU)
            except Exception as e:
                msgs.append(f"{name} (statsmodels) fit failed: {e}")
                return None

        fams = [
            ("Gaussian", GaussianCopula),
            ("Student-t", StudentTCopula),
            ("Clayton", ClaytonCopula),
            ("Gumbel", GumbelCopula),
            ("Frank", FrankCopula),
        ]
        for name, cls in fams:
            out = fit_sm(name, cls)
            if out is not None:
                results.append(out)

    else:
        msgs.append("Aucune librairie de copules trouvée. Installez 'CopulaFurtif' ou 'statsmodels>=0.13'.")

    df = pd.DataFrame(results).sort_values(
        by=["aic", "loglik"], ascending=[True, False], na_position="last"
    ).reset_index(drop=True) if results else pd.DataFrame(
        columns=["name", "params", "loglik", "aic", "tail_dep_L", "tail_dep_U"]
    )
    return df, msgs

# -------------- Dash App --------------
def make_dash_app(artifacts_dir: str, reference_symbol: str):
    dfs, spreads, paths, meta = load_artifacts(artifacts_dir)
    coins_available = sorted(spreads.keys())
    default_coin1 = coins_available[0] if coins_available else None
    default_coin2 = coins_available[1] if len(coins_available) > 1 else None

    app = dash.Dash(__name__, external_stylesheets=[DEFAULT_THEME])
    server = app.server
    app.title = "Cointegration + Copula Lab"

    # Small install helper as HTML (avoid Markdown fenced code)
    install_block = html.Div([
        html.P("Installation conseillée :"),
        html.Pre("pip install statsmodels\npip install CopulaFurtif  # si vous y avez accès"),
    ], style={"backgroundColor": "#222", "color": "#eee", "padding": "12px", "borderRadius": "8px"})

    app.layout = dbc.Container(fluid=True, children=[
        html.H2("Cointegration → Copula Lab", style={'textAlign': 'center'}),
        html.H6("Formation ⇒ screening EG/KSS ⇒ ranking Kendall τ ⇒ sélection paires ⇒ copules (AIC)",
                style={'textAlign': 'center', 'color': '#AAAAAA'}),
        dbc.Row([
            dbc.Col([
                html.Label("Artifacts dir"),
                dcc.Input(id='artifacts-dir', type='text', value=str(Path(artifacts_dir).resolve()), style={'width': '100%'}),
                html.Br(), html.Br(),
                html.Label("Reference asset"),
                dcc.Input(id='ref-asset', type='text', value=reference_symbol, style={'width': '100%'}),
            ], width=3),
            dbc.Col([
                html.Label("Select coins (built spreads vs reference)"),
                dcc.Dropdown(id='coin1', options=[{'label': c, 'value': c} for c in coins_available], value=default_coin1),
                dcc.Dropdown(id='coin2', options=[{'label': c, 'value': c} for c in coins_available], value=default_coin2,
                             style={'marginTop': '6px'}),
                html.Small("Tip: choisissez deux coins parmi les Top-K acceptés (onglet Formation).",
                           style={'color': '#AAAAAA'}),
            ], width=5),
            dbc.Col([
                dbc.Alert(id='lib-info', color='secondary', is_open=True, children=(
                    "Copula backend: " +
                    ("CopulaFurtif ✅" if HAS_COPULAFURTIF else ("statsmodels ✅" if HAS_SM_COPULA else "None ❌"))
                ))
            ], width=4)
        ]),
        html.Hr(),
        dcc.Tabs([
            dcc.Tab(label='Formation (screening & ranking)', children=[
                html.Br(),
                dbc.Row([
                    dbc.Col([
                        html.H5("Summary (coins vs reference)"),
                        dash_table.DataTable(
                            id='tbl-summary',
                            columns=[{"name": c, "id": c} for c in (dfs['summary'].columns if not dfs['summary'].empty else [])],
                            data=(dfs['summary'].to_dict('records') if not dfs['summary'].empty else []),
                            style_table={'overflowX': 'auto'},
                            style_header={'backgroundColor': '#222', 'color': 'white', 'fontWeight': 'bold'},
                            style_data={'backgroundColor': '#111', 'color': 'white'},
                            filter_action='native', sort_action='native', page_size=10
                        )
                    ], width=7),
                    dbc.Col([
                        html.H5("Candidate pairs (among Top-K)"),
                        dash_table.DataTable(
                            id='tbl-pairs',
                            columns=[{"name": c, "id": c} for c in (dfs['pairs'].columns if not dfs['pairs'].empty else [])],
                            data=(dfs['pairs'].to_dict('records') if not dfs['pairs'].empty else []),
                            style_table={'overflowX': 'auto'},
                            style_header={'backgroundColor': '#222', 'color': 'white', 'fontWeight': 'bold'},
                            style_data={'backgroundColor': '#111', 'color': 'white'},
                            sort_action='native', page_size=10
                        ),
                        html.Br(),
                        dcc.Graph(
                            id='adf-hist',
                            figure=(px.histogram(dfs['summary'], x='adf_pvalue', nbins=30, title='Distribution des p-values ADF')
                                    .update_layout(template='plotly_dark') if not dfs['summary'].empty else go.Figure()),
                            config={"displayModeBar": False}
                        )
                    ], width=5),
                ]),
                html.Br(),
                # Use simple HTML + LaTeX-friendly text (no fenced code). MathJax is enabled with dcc.Markdown.
                dcc.Markdown(
                    r"""
### Rappel cointegration (Engle–Granger + KSS)

Pour chaque coin \(i\), on construit le **spread vs référence** \(S_i\) :
\[
S_i(t) = P_{\mathrm{ref}}(t) - \hat\beta_i\, P_i(t), \qquad
\hat\beta_i = \arg\min_\beta \sum_t \big(P_{\mathrm{ref}}(t) - \beta P_i(t)\big)^2.
\]

**ADF sur \(S_i\)** (H0: racine unitaire) : retenir si \(p\text{-value} < \alpha\).
**KSS** (non-linéaire) : \(\Delta S_t = \delta S_{t-1}^3 + \varepsilon_t\), rejeter H0 si \(t < -1.92\) (10%).
Parmi les spreads **acceptés**, classer via \(|\tau|\) de **Kendall** entre \(S_i\) et \(P_{\mathrm{ref}}\), garder les **Top–K**.
                    """,
                    mathjax=True,
                    style={'backgroundColor': '#222', 'color': '#eee', 'padding': '16px'}
                ),
            ]),
            dcc.Tab(label='Copula — fit & diagnostics', children=[
                html.Br(),
                dbc.Row([
                    dbc.Col([
                        dcc.Graph(id='uv-scatter', config={"displayModeBar": False}),
                        dcc.Graph(id='uv-empirical', config={"displayModeBar": False}),
                    ], width=6),
                    dbc.Col([
                        html.H5("Fit candidate copulas"),
                        html.Div(id='fit-messages', style={'color': '#FFDD57'}),
                        dash_table.DataTable(
                            id='tbl-copula',
                            columns=[{"name": c, "id": c} for c in ['name', 'params', 'loglik', 'aic', 'tail_dep_L', 'tail_dep_U']],
                            data=[],
                            style_table={'overflowX': 'auto'},
                            style_header={'backgroundColor': '#222', 'color': 'white', 'fontWeight': 'bold'},
                            style_data={'backgroundColor': '#111', 'color': 'white'},
                            sort_action='native', page_size=8
                        ),
                        html.Br(),
                        html.Div(id='best-copula-card')
                    ], width=6),
                ]),
                html.Br(),
                dcc.Markdown(
                    r"""
### Copules — notions utiles

**Copule** \(C(u,v)\) : couple des marges uniformes \(U,V\sim\mathcal U(0,1)\) pour former \(F_{X,Y}(x,y)=C(F_X(x), F_Y(y))\).
On travaille donc sur **pseudo-observations** \(u=\hat F_X(x), v=\hat F_Y(y)\).

**Vraisemblance.** Pour \((u_k,v_k)\), \(\log L(\theta) = \sum_k \log c(u_k,v_k;\theta)\) avec \(c=\partial^2 C/(\partial u\,\partial v)\).
Critère **AIC** : \(\mathrm{AIC}=2k-2\log L\).

**Dépendance de queue.**
Clayton : \(\lambda_L=2^{-1/\theta}, \lambda_U=0\);
Gumbel : \(\lambda_L=0, \lambda_U=2-2^{1/\theta}\);
Student-t : \(\lambda_L=\lambda_U>0\) (fonction de \(\rho,\nu\)).
                    """,
                    mathjax=True,
                    style={'backgroundColor': '#222', 'color': '#eee', 'padding': '16px'}
                ),
            ]),
            dcc.Tab(label='Aide & prérequis', children=[
                html.Br(),
                html.Div([
                    html.P("Backends copules :"),
                    html.Ul([
                        html.Li("CopulaFurtif (prioritaire si présent)."),
                        html.Li("statsmodels ≥ 0.13 : Gaussian / Student-t / Clayton / Gumbel / Frank."),
                        html.Li("Sinon : pas de fit (mais vues empiriques disponibles)."),
                    ], style={"marginBottom": "10px"}),
                    install_block,
                ], style={'backgroundColor': '#222', 'color': '#eee', 'padding': '16px', 'borderRadius': '8px'})
            ]),
        ])
    ], style={'backgroundColor': '#181818', 'color': '#EEE'})

    @app.callback(
        Output('uv-scatter', 'figure'),
        Output('uv-empirical', 'figure'),
        Output('tbl-copula', 'data'),
        Output('fit-messages', 'children'),
        Output('best-copula-card', 'children'),
        Input('coin1', 'value'),
        Input('coin2', 'value'),
        State('artifacts-dir', 'value'),
        prevent_initial_call=False
    )
    def update_copula_views(c1, c2, artifacts_dir):
        empty = go.Figure().update_layout(template='plotly_dark', title='Sélectionnez deux coins distincts')
        if not c1 or not c2 or c1 == c2:
            return empty, empty, [], "Choisissez deux coins.", None

        base = Path(artifacts_dir) / 'spreads'
        f1, f2 = base / f"{c1}.csv", base / f"{c2}.csv"
        if not (f1.exists() and f2.exists()):
            msg = f"Fichiers manquants: {f1.name if not f1.exists() else ''} {f2.name if not f2.exists() else ''}".strip()
            return empty, empty, [], msg, None

        s1 = pd.read_csv(f1, index_col=0, parse_dates=True).iloc[:, 0]
        s2 = pd.read_csv(f2, index_col=0, parse_dates=True).iloc[:, 0]
        s1, s2 = s1.align(s2, join='inner')
        if s1.empty or s2.empty:
            return empty, empty, [], "Pas assez de données communes.", None

        u, v = pseudo_obs(s1), pseudo_obs(s2)
        if len(u) == 0 or len(v) == 0:
            return empty, empty, [], "Impossible de former des pseudo-observations.", None

        fig_sc = fig_scatter_uv(u, v)
        fig_emp = fig_empirical_copula(u, v, nbins=35)

        df_fit, msgs = fit_copulas(u, v)
        msg_box = html.Ul([html.Li(m) for m in msgs]) if msgs else ""

        if not df_fit.empty:
            best = df_fit.iloc[0]
            tdL = best.get('tail_dep_L', np.nan)
            tdU = best.get('tail_dep_U', np.nan)
            tdL_txt = "{:.3f}".format(tdL) if isinstance(tdL, (int, float, np.floating)) else str(tdL)
            tdU_txt = "{:.3f}".format(tdU) if isinstance(tdU, (int, float, np.floating)) else str(tdU)
            card = dbc.Card([
                dbc.CardHeader("Best by AIC"),
                dbc.CardBody([
                    html.H4(str(best['name'])),
                    html.P(f"AIC = {best['aic']:.2f} | loglik = {best['loglik']:.2f}"),
                    html.P(f"params = {np.array2string(best['params'], precision=3)}"),
                    html.P(f"Tail dep. λL={tdL_txt}, λU={tdU_txt}"),
                ])
            ], color="dark", inverse=True)
        else:
            card = None

        return fig_sc, fig_emp, df_fit.to_dict('records'), msg_box, card

    return app


def main():
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('--artifacts', type=str, default='./artifacts')
    parser.add_argument('--reference', type=str, default='BTCUSDT')
    args = parser.parse_args()

    app = make_dash_app(args.artifacts, args.reference)
    app.run(debug=True, host='0.0.0.0', port=8042)


if __name__ == "__main__":
    main()
